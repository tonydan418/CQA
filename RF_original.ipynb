{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CQA Random Forest Prediction \n",
    "In this code file, we have converted the original code scheme of LASSO regression to a simple random forest classification scheme. \n",
    "In addition, there is a bug in the original code for backtesting that we fixed as well.\n",
    "Modified code sections are highlighted with red captions.(Color highlighter can be installed via the Jupyter nbextension package: https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/highlighter/readme.html).\n",
    "\n",
    "delayed return  \n",
    "84_Q data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('64bit', 'WindowsPE')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import platform\n",
    "platform.architecture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import alpha library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data_matrix1 = pd.read_csv(\"C:\\\\Users\\\\tony\\\\Desktop\\\\CQA\\\\data\\\\data_matrix_20_Q.csv\")\n",
    "data_matrix2 = pd.read_csv(\"C:\\\\Users\\\\tony\\\\Desktop\\\\CQA\\\\data\\\\data_matrix_21_to_40_Q.csv\")\n",
    "data_matrix3 = pd.read_csv(\"C:\\\\Users\\\\tony\\\\Desktop\\\\CQA\\\\data\\\\data_matrix_41_to_60_Q.csv\")\n",
    "data_matrix4 = pd.read_csv(\"C:\\\\Users\\\\tony\\\\Desktop\\\\CQA\\\\data\\\\data_matrix_61_to_84_Q.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = pd.concat([data_matrix1,data_matrix2,data_matrix3,data_matrix4],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### monthly return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_returns = data_matrix[['asOfDate','tic','Return']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tics = data_matrix['tic']\n",
    "dates = data_matrix['asOfDate']\n",
    "dates = dates.apply(lambda x: x[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separate dates, returns (label) and alphas (data) from data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALPHA_77</th>\n",
       "      <th>ALPHA_267</th>\n",
       "      <th>ALPHA_505</th>\n",
       "      <th>ALPHA_572</th>\n",
       "      <th>ALPHA_25</th>\n",
       "      <th>SPPIVY</th>\n",
       "      <th>ALPHA_129</th>\n",
       "      <th>ALPHA_264</th>\n",
       "      <th>OPMBD</th>\n",
       "      <th>OPMBD1</th>\n",
       "      <th>...</th>\n",
       "      <th>IBCOMY</th>\n",
       "      <th>DOQ</th>\n",
       "      <th>DOY</th>\n",
       "      <th>IBADJQ</th>\n",
       "      <th>IBQ</th>\n",
       "      <th>IBADJY</th>\n",
       "      <th>IBY</th>\n",
       "      <th>CSH12Q</th>\n",
       "      <th>CSHPRQ</th>\n",
       "      <th>CSHPRY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.129319</td>\n",
       "      <td>0.053984</td>\n",
       "      <td>0.306399</td>\n",
       "      <td>0.346287</td>\n",
       "      <td>-0.066755</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.028620</td>\n",
       "      <td>0.287070</td>\n",
       "      <td>0.287070</td>\n",
       "      <td>...</td>\n",
       "      <td>9705.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3253.0</td>\n",
       "      <td>3253.0</td>\n",
       "      <td>9705.0</td>\n",
       "      <td>9705.0</td>\n",
       "      <td>905.3295</td>\n",
       "      <td>912.197</td>\n",
       "      <td>907.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.273262</td>\n",
       "      <td>-0.003845</td>\n",
       "      <td>0.233960</td>\n",
       "      <td>-0.231986</td>\n",
       "      <td>-0.166918</td>\n",
       "      <td>-771.0</td>\n",
       "      <td>1.056310</td>\n",
       "      <td>-1.211370</td>\n",
       "      <td>0.295827</td>\n",
       "      <td>0.295827</td>\n",
       "      <td>...</td>\n",
       "      <td>5617.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2741.0</td>\n",
       "      <td>3123.0</td>\n",
       "      <td>5331.0</td>\n",
       "      <td>6305.0</td>\n",
       "      <td>9102.1828</td>\n",
       "      <td>9956.773</td>\n",
       "      <td>9570.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.323743</td>\n",
       "      <td>0.103459</td>\n",
       "      <td>0.204940</td>\n",
       "      <td>0.259946</td>\n",
       "      <td>1.604720</td>\n",
       "      <td>-1061.0</td>\n",
       "      <td>1.980420</td>\n",
       "      <td>-0.135714</td>\n",
       "      <td>0.300105</td>\n",
       "      <td>0.300105</td>\n",
       "      <td>...</td>\n",
       "      <td>6917.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>2674.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>6860.0</td>\n",
       "      <td>6917.0</td>\n",
       "      <td>23195.6250</td>\n",
       "      <td>28849.400</td>\n",
       "      <td>28646.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.055053</td>\n",
       "      <td>0.058377</td>\n",
       "      <td>0.426733</td>\n",
       "      <td>2.559450</td>\n",
       "      <td>-0.082981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.536183</td>\n",
       "      <td>0.816442</td>\n",
       "      <td>0.414490</td>\n",
       "      <td>0.414490</td>\n",
       "      <td>...</td>\n",
       "      <td>18760.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4518.0</td>\n",
       "      <td>4518.0</td>\n",
       "      <td>18760.0</td>\n",
       "      <td>18760.0</td>\n",
       "      <td>8813.0000</td>\n",
       "      <td>8712.000</td>\n",
       "      <td>8813.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.127456</td>\n",
       "      <td>0.058582</td>\n",
       "      <td>0.412080</td>\n",
       "      <td>1.127290</td>\n",
       "      <td>-0.024606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.159110</td>\n",
       "      <td>0.396041</td>\n",
       "      <td>0.396041</td>\n",
       "      <td>...</td>\n",
       "      <td>3795.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>3795.0</td>\n",
       "      <td>3795.0</td>\n",
       "      <td>317.4950</td>\n",
       "      <td>318.350</td>\n",
       "      <td>318.123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 474 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ALPHA_77  ALPHA_267  ALPHA_505  ALPHA_572  ALPHA_25  SPPIVY  ALPHA_129  \\\n",
       "0 -0.129319   0.053984   0.306399   0.346287 -0.066755    14.0   0.000000   \n",
       "1 -0.273262  -0.003845   0.233960  -0.231986 -0.166918  -771.0   1.056310   \n",
       "2 -0.323743   0.103459   0.204940   0.259946  1.604720 -1061.0   1.980420   \n",
       "3 -0.055053   0.058377   0.426733   2.559450 -0.082981     NaN   0.536183   \n",
       "4 -0.127456   0.058582   0.412080   1.127290 -0.024606     0.0   0.000000   \n",
       "\n",
       "   ALPHA_264     OPMBD    OPMBD1    ...       IBCOMY  DOQ    DOY  IBADJQ  \\\n",
       "0   2.028620  0.287070  0.287070    ...       9705.0  0.0    0.0  3253.0   \n",
       "1  -1.211370  0.295827  0.295827    ...       5617.0  0.0    0.0  2741.0   \n",
       "2  -0.135714  0.300105  0.300105    ...       6917.0 -3.0  208.0  2674.0   \n",
       "3   0.816442  0.414490  0.414490    ...      18760.0  0.0    0.0  4518.0   \n",
       "4   1.159110  0.396041  0.396041    ...       3795.0  0.0    0.0  1840.0   \n",
       "\n",
       "      IBQ   IBADJY      IBY      CSH12Q     CSHPRQ     CSHPRY  \n",
       "0  3253.0   9705.0   9705.0    905.3295    912.197    907.762  \n",
       "1  3123.0   5331.0   6305.0   9102.1828   9956.773   9570.166  \n",
       "2  2700.0   6860.0   6917.0  23195.6250  28849.400  28646.900  \n",
       "3  4518.0  18760.0  18760.0   8813.0000   8712.000   8813.000  \n",
       "4  1840.0   3795.0   3795.0    317.4950    318.350    318.123  \n",
       "\n",
       "[5 rows x 474 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = [i for i in range(14,488)]\n",
    "alpha_library = data_matrix.iloc[:,mask]\n",
    "alpha_library.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function1: delete columns with too many nan \n",
    "input:    \n",
    "data -- dataframe;   \n",
    "ratio -- threshold of (number of NA's)/(data size);\n",
    "      \n",
    "output:    \n",
    "data -- dataframe which the ratio less than threshold ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete columns with too many nan\n",
    "def delete_columns_with_too_many_nan(data, ratio):\n",
    "    return data.loc[:,data.isnull().mean()<(ratio)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After delete all the alpha with >0.1 NA's, the alpha library contains 464 alphas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252000, 474)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_library = delete_columns_with_too_many_nan(alpha_library, 0.1)\n",
    "alpha_library.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function2: replace NA's with mean in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nan with mean\n",
    "def replace_nan_with_mean(data):\n",
    "    col_names = list(data)\n",
    "    col_mean = np.nanmean(data, axis=0)\n",
    "    values = {}\n",
    "    for i in range(len(col_names)):\n",
    "        values[col_names[i]] = col_mean[i]\n",
    "    return data.fillna(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_library = replace_nan_with_mean(alpha_library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function3: data mask\n",
    "input:   \n",
    "start_year,start_quarter,train_time,delay\n",
    "\n",
    "output:   \n",
    "training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_delay(start_year,start_month,delay):\n",
    "    if start_month<10:\n",
    "        start_time = str(start_year)+'-0'+str(start_month)\n",
    "    else:\n",
    "        start_time = str(start_year)+'-'+str(start_month)    \n",
    "    \n",
    "    response_month = start_month+delay\n",
    "    if response_month>12:\n",
    "        response_year = start_year+1\n",
    "        response_month = response_month-12\n",
    "    else:\n",
    "        response_year = start_year\n",
    "        \n",
    "    if response_month<10:\n",
    "        response_time = str(response_year)+'-0'+str(response_month)\n",
    "    else:\n",
    "        response_time = str(response_year)+'-'+str(response_month)\n",
    "        \n",
    "    return start_time,response_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"burk\">\n",
    "    At this point, if we just leave the code as it is, then testing set would be the same as the training set. \n",
    "    In other words, train_x would be in the same period as test_x, while train_Y would be in the same period as test_Y.\n",
    "    And thus the backtesting would be invalid..\n",
    "    \n",
    "    Therefore, we have proposed to roll over the testing dataset one month, and the following convert_to_test function implements this goal.\n",
    "</div><i class=\"fa fa-lightbulb-o \"></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_test(start_year,start_month,delay):\n",
    "    #normal addition process\n",
    "    #if start_month <12:\n",
    "    if start_month <9:\n",
    "        start_yr = start_year\n",
    "        #start_m = start_month +1\n",
    "        start_m = start_month +delay\n",
    "        \n",
    "    #adding another year\n",
    "    else: \n",
    "        start_yr = start_year + 1 \n",
    "        #start_m = 1 \n",
    "        start_m = start_month + delay - 12\n",
    "    \n",
    "    return start_yr, start_m \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_train(alpha_library,monthly_returns,dates,tics,start_year,start_month,delay):\n",
    "    start_time,response_time = monthly_delay(start_year,start_month,delay)\n",
    "    \n",
    "    train_mask = dates == start_time\n",
    "    train_alpha  = alpha_library[train_mask]\n",
    "    train_tic = list(tics[train_mask])\n",
    "    \n",
    "    ###\n",
    "    response_mask = dates == response_time\n",
    "    response_return = monthly_returns['Return'][response_mask]\n",
    "    response_tic = monthly_returns['tic'][response_mask]\n",
    "\n",
    "    # create a tic-return dictionary\n",
    "    response_dict = dict([(i,j) for i,j in zip(response_tic,response_return)])\n",
    "\n",
    "    # create returns\n",
    "    train_Y = np.zeros([train_alpha.shape[0],1])\n",
    "    for i in range(len(train_tic)):\n",
    "        if train_tic[i] in response_dict:\n",
    "            train_Y[i] = response_dict[train_tic[i]]\n",
    "        else:\n",
    "            train_Y[i] = None\n",
    "            \n",
    "    train_Y = pd.DataFrame(train_Y)\n",
    "    \n",
    "    # filter nan in returns\n",
    "    train_alpha['label'] = train_Y.values\n",
    "    train_Y = train_alpha.loc[~train_alpha['label'].isnull(),'label']\n",
    "    train_X = train_alpha.loc[~train_alpha['label'].isnull(),].drop(columns=['label'])\n",
    "\n",
    "    return train_X,train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_test(alpha_library,monthly_returns,dates,tics,start_year,start_month,delay):\n",
    "    start_time,response_time = monthly_delay(start_year,start_month,delay)\n",
    "    ###\n",
    "    test_mask = dates == start_time\n",
    "    test_X  = alpha_library[test_mask]\n",
    "    test_tic = list(tics[test_mask])\n",
    "\n",
    "    return test_X,test_tic,response_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data files\n",
    "import os \n",
    "returns_folder = \"C:\\\\Users\\\\tony\\\\Desktop\\\\CQA\\\\data\\\\dr\\\\\"\n",
    "files_list = os.listdir(returns_folder)\n",
    "files_list = sorted(files_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two different strategy for the portfolio management.   \n",
    "(1) invest one (or negetive one) dollar every day for each company  \n",
    "(2) invest one(or negetive one) dollar in the beginning of every month for each company  \n",
    "\n",
    "The following function is based on assumption (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_monthly_returns(date,files_list,returns_folder,returns,x):\n",
    "    daily_returns = pd.DataFrame([], columns=('date','portfolio_value','portfolio_return'))\n",
    "    i = 0\n",
    "    for temp_file in files_list:\n",
    "        if date in temp_file:\n",
    "            return_temp = pd.read_csv(returns_folder+temp_file)\n",
    "            return_temp = return_temp.dropna()\n",
    "        \n",
    "            for j in range(return_temp.shape[0]):\n",
    "                if return_temp.iloc[j,0] in returns:\n",
    "                    comp_tic = return_temp.iloc[j,0]\n",
    "                    returns[comp_tic] = returns[comp_tic]*(1+return_temp.iloc[j,1])\n",
    "            daily_returns.loc[i] = [pd.Timestamp(temp_file[:10]),x+sum(returns.values()),None]\n",
    "            if i>0:\n",
    "                daily_returns['portfolio_return'][i] = (daily_returns['portfolio_value'][i]-daily_returns['portfolio_value'][i-1])/daily_returns['portfolio_value'][i-1]\n",
    "            else:\n",
    "                daily_returns['portfolio_return'][i] = (daily_returns['portfolio_value'][i]-x)/x\n",
    "            i = i+1\n",
    "    month_return = (daily_returns['portfolio_value'][i-1]-x)/x\n",
    "\n",
    "    return daily_returns,month_return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"burk\">\n",
    "    The following iterative algorithm performs a backtesting of Random Forest Prediction based on the specified dataset.s\n",
    "    We have include the convert_to_test function to roll over testing set one month, to fix the bug in the code.\n",
    "    \n",
    "</div><i class=\"fa fa-lightbulb-o \"></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portfolio_return for 2011-05 is  0.005259231623340188\n",
      "portfolio_return for 2011-06 is  0.01257541928316422\n",
      "portfolio_return for 2011-07 is  -0.0008087966022396766\n",
      "portfolio_return for 2011-08 is  0.0033767231353075008\n",
      "portfolio_return for 2011-09 is  0.007844401561804108\n",
      "portfolio_return for 2011-10 is  0.0023860036994668814\n",
      "portfolio_return for 2011-11 is  5.47446863912463e-05\n",
      "portfolio_return for 2011-12 is  -0.002837760646312245\n",
      "portfolio_return for 2012-01 is  0.014540563412683812\n",
      "portfolio_return for 2012-02 is  -0.00013582509606075514\n",
      "portfolio_return for 2012-03 is  0.011327495722335015\n",
      "portfolio_return for 2012-04 is  0.002510300318641784\n",
      "portfolio_return for 2012-05 is  -0.007959913913255755\n",
      "portfolio_return for 2012-06 is  -0.0011093148406460373\n",
      "portfolio_return for 2012-07 is  0.006210557604297865\n",
      "portfolio_return for 2012-08 is  0.00021374518888158246\n",
      "portfolio_return for 2012-09 is  -0.013995649609519505\n",
      "portfolio_return for 2012-10 is  0.005699162093866223\n",
      "portfolio_return for 2012-11 is  0.007496871308875842\n",
      "portfolio_return for 2012-12 is  0.004917223220356613\n",
      "portfolio_return for 2013-01 is  0.0018831698271977073\n",
      "portfolio_return for 2013-02 is  0.002792472608385824\n",
      "portfolio_return for 2013-03 is  -0.00013147135197933986\n",
      "portfolio_return for 2013-04 is  0.01024936213414966\n",
      "portfolio_return for 2013-05 is  -0.0035229739236635675\n",
      "portfolio_return for 2013-06 is  0.001985005274402942\n",
      "portfolio_return for 2013-07 is  -0.0042694106331849025\n",
      "portfolio_return for 2013-08 is  0.003645951180230717\n",
      "portfolio_return for 2013-09 is  0.005422976121275739\n",
      "portfolio_return for 2013-10 is  0.006376974792737243\n",
      "portfolio_return for 2013-11 is  0.0005929275220414343\n",
      "portfolio_return for 2013-12 is  0.002576573685637233\n",
      "portfolio_return for 2014-01 is  -0.013023170767157827\n",
      "portfolio_return for 2014-02 is  0.0009681764408371487\n",
      "portfolio_return for 2014-03 is  -0.0017233935946082532\n",
      "portfolio_return for 2014-04 is  -0.0027501470051102947\n",
      "portfolio_return for 2014-05 is  0.007310873806060136\n",
      "portfolio_return for 2014-06 is  -0.009299674865175097\n",
      "portfolio_return for 2014-07 is  0.007335944433362326\n",
      "portfolio_return for 2014-08 is  0.0008016430289666266\n",
      "portfolio_return for 2014-09 is  0.0015476314902720125\n",
      "portfolio_return for 2014-10 is  -0.008547623054317005\n",
      "portfolio_return for 2014-11 is  0.009555524982302027\n",
      "portfolio_return for 2014-12 is  -0.0076949838684873895\n",
      "portfolio_return for 2015-01 is  0.006123996304749522\n",
      "portfolio_return for 2015-02 is  -0.0008770191355109099\n",
      "portfolio_return for 2015-03 is  0.0177829581669418\n",
      "portfolio_return for 2015-04 is  -0.007431760746676822\n",
      "portfolio_return for 2015-05 is  0.009619463651750275\n",
      "portfolio_return for 2015-06 is  0.013054843968318184\n",
      "portfolio_return for 2015-07 is  -0.012975360552023009\n",
      "portfolio_return for 2015-08 is  -0.004302773582666966\n",
      "portfolio_return for 2015-09 is  0.011321201020913094\n",
      "portfolio_return for 2015-10 is  -0.0030569553361711665\n",
      "portfolio_return for 2015-11 is  -0.012946967212877303\n",
      "portfolio_return for 2015-12 is  0.013409028621161058\n",
      "portfolio_return for 2016-01 is  0.015192166118401254\n",
      "portfolio_return for 2016-02 is  -0.005951198458207388\n",
      "portfolio_return for 2016-03 is  -0.014624923411765814\n",
      "portfolio_return for 2016-04 is  -0.021642323515435193\n",
      "portfolio_return for 2016-05 is  0.001201884620630736\n",
      "portfolio_return for 2016-06 is  0.0031162464953993587\n",
      "portfolio_return for 2016-07 is  0.001192244318410422\n",
      "portfolio_return for 2016-08 is  0.0010473215017046534\n",
      "portfolio_return for 2016-09 is  -0.0025544379089433057\n",
      "portfolio_return for 2016-10 is  0.010157515192039937\n",
      "portfolio_return for 2016-11 is  0.015443412363590883\n",
      "portfolio_return for 2016-12 is  -0.006479098585463433\n",
      "portfolio_return for 2017-01 is  -0.0003515805779851345\n",
      "portfolio_return for 2017-02 is  -0.009360486552159016\n",
      "portfolio_return for 2017-03 is  -0.007680839588695939\n",
      "portfolio_return for 2017-04 is  0.003445040504173459\n",
      "portfolio_return for 2017-05 is  0.004522576150278883\n",
      "portfolio_return for 2017-06 is  -0.0032319961464208013\n",
      "portfolio_return for 2017-07 is  0.0035421235858518947\n",
      "portfolio_return for 2017-08 is  0.003846325090045963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "delay = 4 # delay\n",
    "m = 1500 # number_of_stocks\n",
    "portfolio_returns = pd.DataFrame([], columns=('date','portfolio_return'))\n",
    "portfolio_daily_returns = pd.DataFrame([], columns=('date','portfolio_value','portfolio_return'))\n",
    "i = 0\n",
    "set_dates = list(sorted(set(dates)))\n",
    "x = 1\n",
    "#for k in range(len(set_dates)-delay):\n",
    "#for k in range(len(set_dates)-delay-1):\n",
    "for k in range(len(set_dates)-delay-delay):\n",
    "    date = set_dates[i]\n",
    "    start_year = int(date[:4])\n",
    "    start_month = int(date[5:7])\n",
    "    \n",
    "    train_X,train_Y = retrive_train(alpha_library,monthly_returns,dates,tics,start_year,start_month,delay)\n",
    "    #test_X,test_tic,response_time = retrive_test(alpha_library,monthly_returns,dates,tics,start_year,start_month,delay)\n",
    "    \n",
    "    ###############################################\n",
    "    ##############################################\n",
    "    ##############################################\n",
    "    #roll over the relationship one period ahead, to fix the bug\n",
    "    start_y, start_m = convert_to_test(start_year,start_month,delay)\n",
    "    test_X,test_tic,response_time = retrive_test(alpha_library,monthly_returns,dates,tics,start_y,start_m,delay)\n",
    "    ################################################\n",
    "    ################################################\n",
    "    ###############################################\n",
    "\n",
    "    #convert to binary return of Buy/sell\n",
    "    train_Y = np.where(train_Y > np.repeat(0, len(train_Y)), \"Buy\",\"Sell\")\n",
    "\n",
    "    #create random forest object\n",
    "    rf = RandomForestClassifier()\n",
    "    # Train the model on training data\n",
    "    rf.fit(train_X, train_Y);\n",
    "    #make predictions using testing set \n",
    "    pred_Y_rf = rf.predict(test_X)\n",
    "    \n",
    "    #long the stocks that classify as Buy, and short the stocks that classify as sell\n",
    "    companies = test_tic\n",
    "    pred = dict(zip(companies, pred_Y_rf))\n",
    "\n",
    "    #create an equal weighted dollar-neutral portfolio#\n",
    "    \n",
    "    #number of longing stocks in the dollar-neutral portfolio\n",
    "    ls = np.where(pred_Y_rf == 'Buy', 1,0)\n",
    "    nl = sum(ls)\n",
    "    \n",
    "     #number of shorting stocks in the dollar-neutral portfolio\n",
    "    ss = np.where(pred_Y_rf == 'Sell',1,0)\n",
    "    ns = sum(ss)\n",
    "    \n",
    "    returns = {}\n",
    "    for j in companies:\n",
    "        if pred[j] == 'Buy':\n",
    "            returns[j] = x/nl/2\n",
    "        else: \n",
    "            returns[j] = -x/ns/2\n",
    "\n",
    "    \n",
    "    #calculate monthly portfolio return\n",
    "    daily_returns,portfolio_return = portfolio_monthly_returns(response_time,files_list,returns_folder,returns,x)\n",
    "    print('portfolio_return for',response_time, 'is ',portfolio_return)\n",
    "    \n",
    "    portfolio_daily_returns = pd.concat([portfolio_daily_returns, daily_returns], ignore_index=True)\n",
    "    portfolio_returns.loc[i] = [pd.Timestamp(response_time),portfolio_return]\n",
    "    i = i+1\n",
    "    x = daily_returns.iloc[-1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portfolio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c9cdedf208>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "aggregate = [1]\n",
    "for i in portfolio_daily_returns['portfolio_return']:\n",
    "    aggregate.append(aggregate[-1]*(i+1))\n",
    "aggregate = aggregate[1:]\n",
    "plt.plot(portfolio_daily_returns['date'],aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_daily_returns = portfolio_daily_returns.set_index(portfolio_daily_returns['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_return(returns):\n",
    "    return 252*np.mean(returns)*100\n",
    "    \n",
    "def vol(returns):\n",
    "    return np.sqrt(252)*np.std(returns)*100\n",
    "\n",
    "def sharpe_ratio(returns):\n",
    "    return np.sqrt(252)*np.mean(returns)/np.std(returns)\n",
    "\n",
    "def Sortino(returns):\n",
    "    return np.sqrt(252)*np.mean(returns)/np.std(returns[returns<0])\n",
    "\n",
    "def draw_down(returns):\n",
    "    # We are going to use a trailing 252 trading day window\n",
    "    window = 252\n",
    "    # Calculate the max drawdown in the past window days for each day in the series.\n",
    "    # Use min_periods=1 if you want to let the first 252 days data have an expanding window\n",
    "    #Roll_Max = pd.rolling_max(returns, window, min_periods=1)\n",
    "    \n",
    "    Roll_Max = returns.rolling(window,min_periods = 1).max()\n",
    "    Daily_Drawdown = returns/Roll_Max - 1.0\n",
    "\n",
    "    # Then we calculate the minimum daily drawdown, which is equivalent to maximum drawdown \n",
    "    # Again, use min_periods=1 if you want to allow the expanding window\n",
    "    #Max_Daily_Drawdown = pd.rolling_min(Daily_Drawdown, window, min_periods=1)\n",
    "    Max_Daily_Drawdown = Daily_Drawdown.rolling(window,min_periods = 1).min()\n",
    "    return Max_Daily_Drawdown\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.1904791294488803\n",
      "year 2011, mean return = 4.1393, Volatility = 3.9640, sharpe ratio = 1.0442, Max_Drawdown Rate = -3.1905, Sortino ratio = 1.2788\n",
      "-2.9847768223888425\n",
      "year 2012, mean return = 2.9904, Volatility = 2.9947, sharpe ratio = 0.9986, Max_Drawdown Rate = -2.9848, Sortino ratio = 1.2880\n",
      "-2.272647009671036\n",
      "year 2013, mean return = 2.7740, Volatility = 2.2667, sharpe ratio = 1.2238, Max_Drawdown Rate = -2.2726, Sortino ratio = 1.7779\n",
      "-7.930414450473524\n",
      "year 2014, mean return = -1.5474, Volatility = 2.6333, sharpe ratio = -0.5876, Max_Drawdown Rate = -7.9304, Sortino ratio = -0.9157\n",
      "-2.0120566610720285\n",
      "year 2015, mean return = 2.9798, Volatility = 3.8615, sharpe ratio = 0.7717, Max_Drawdown Rate = -2.0121, Sortino ratio = 1.1444\n",
      "-1.9422908392234541\n",
      "year 2016, mean return = -0.4121, Volatility = 3.0278, sharpe ratio = -0.1361, Max_Drawdown Rate = -1.9423, Sortino ratio = -0.2142\n"
     ]
    }
   ],
   "source": [
    "for year in range(2011,2017):\n",
    "    returns = portfolio_daily_returns[str(year)+'-01-01':str(year+1)+'-01-01']['portfolio_return']\n",
    "    #print(len(returns))\n",
    "    print(draw_down(returns)[-1])\n",
    "    print('year %4d, mean return = %.4f, Volatility = %.4f, sharpe ratio = %.4f, Max_Drawdown Rate = %.4f, Sortino ratio = %.4f' % \\\n",
    "          (year,mean_return(returns),vol(returns),sharpe_ratio(returns),draw_down(returns)[-1],Sortino(returns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"burk\">\n",
    "Once we have fix the bug, total portfolio return is positive! \n",
    "    Please note that we haven't used any future information at each step of the iterative backtest. (this is a common error in backtesting!).\n",
    "</div><i class=\"fa fa-lightbulb-o \"></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09177618620860595"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate[-1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
